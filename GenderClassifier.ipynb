{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GenderClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_rXaLY6f_rJ"
      },
      "source": [
        "#Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1IRBGN6gCxm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import functools\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.utils\n",
        "from torch.autograd import Function\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import time\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1k4ZowM2ILdm"
      },
      "source": [
        "#Set device to GPU_indx if GPU is avaliable\n",
        "GPU_indx = 0\n",
        "device = torch.device(GPU_indx if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k39hkZfKf3Pb"
      },
      "source": [
        "# Their Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NptX-R_0fsyG"
      },
      "source": [
        "class GenderClassification(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        super(GenderClassification, self).__init__()\n",
        "        print(\"Build a GenderClassification Model\")\n",
        "\n",
        "        self.base_network = models.resnet18(pretrained = True)\n",
        "        print('Load weights from Resnet18 done')\n",
        "\n",
        "        self.finalLayer = nn.Linear(self.base_network.fc.in_features, 2)\n",
        "\n",
        "    def forward(self, image):\n",
        "        x = self.base_network.conv1(image) \n",
        "        x = self.base_network.bn1(x) \n",
        "        x = self.base_network.relu(x) \n",
        "        x = self.base_network.maxpool(x) \n",
        "\n",
        "        x = self.base_network.layer1(x)\n",
        "        x = self.base_network.layer2(x)\n",
        "        x = self.base_network.layer3(x)\n",
        "        x = self.base_network.layer4(x)\n",
        "\n",
        "        x = self.base_network.avgpool(x)\n",
        "        image_features = x.view(x.size(0), -1)\n",
        "\n",
        "        preds = self.finalLayer(image_features)\n",
        "\n",
        "        return preds"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fm_mNsdG-qe",
        "outputId": "eeec4e7a-52cf-4d44-a748-9a0ae428bd81"
      },
      "source": [
        "gender_classifier1 = GenderClassification()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Build a GenderClassification Model\n",
            "Load weights from Resnet18 done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEUNaYuVyz6m"
      },
      "source": [
        "# Easy Resnet Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI4_uMJDHC9I"
      },
      "source": [
        "gender_classifier2 = models.resnet18(pretrained=True)\n",
        "input_feat = gender_classifier2.fc.in_features\n",
        "gender_classifier2.fc = nn.Linear(in_features = input_feat, out_features = 2, bias = True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BjNcL7mE4w1"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5yEnfe_E4dC"
      },
      "source": [
        "num_epochs = 100\n",
        "\n",
        "lr = 0.05\n",
        "optimizer = optim.Adam(gender_classifier2.parameters(), lr=lr, weight_decay = 1e-5)\n",
        "loss_fun = torch.nn.CrossEntropyLoss() # F.cross_entropy(adv_pred, genders.cuda().max(1, keepdim=False)[1], reduction='elementwise_mean')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsv73ws8FwNG"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD4l0a3iFxSZ"
      },
      "source": [
        "def train(net, device, loader, optimizer, loss_fun):\n",
        "    \n",
        "    #initialise counters\n",
        "    epoch_loss = 0\n",
        "    \n",
        "    #Set Network in train mode\n",
        "    net.train()\n",
        "    \n",
        "    for i, (x, y) in enumerate(loader):\n",
        "        \n",
        "        #load images and labels to device\n",
        "        x = x.to(device) # x is the image\n",
        "        y = y.to(device) # y is the corresponding label\n",
        "                \n",
        "        #Forward pass of image through network and get output\n",
        "        fx = net(x)\n",
        "        \n",
        "        #Calculate loss using loss function\n",
        "        loss = loss_fun(fx, y)\n",
        "\n",
        "        #Zero Gradents\n",
        "        optimizer.zero_grad()\n",
        "        #Backpropagate Gradents\n",
        "        loss.backward()\n",
        "        #Do a single optimization step\n",
        "        optimizer.step()\n",
        "        \n",
        "        #create the cumulative sum of the loss and acc\n",
        "        epoch_loss += loss.item()\n",
        "        #log the loss for plotting\n",
        "\n",
        "    epoch_loss /=  len(loader)\n",
        "        \n",
        "    #return the average loss from the epoch as well as the logger array       \n",
        "    return epoch_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHHxC0WbFyJF"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySfa0w2_FzqL"
      },
      "source": [
        "def evaluate(net, device, loader, loss_fun):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    #Set network in evaluation mode\n",
        "    #Layers like Dropout will be disabled\n",
        "    #Layers like Batchnorm will stop calculating running mean and standard deviation\n",
        "    #and use current stored values\n",
        "    net.eval()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(loader):\n",
        "            \n",
        "            #load images and labels to device\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            \n",
        "            #Forward pass of image through network\n",
        "            fx = net(x)\n",
        "            \n",
        "            #Calculate loss using loss function\n",
        "            loss = loss_fun(fx, y)\n",
        "            \n",
        "            #calculate the accuracy\n",
        "            epoch_acc += (fx.argmax(1) == y).sum().item()\n",
        "            \n",
        "            #log the cumulative sum of the loss\n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "    epoch_loss /=  len(loader)\n",
        "    epoch_acc /=  len(loader.dataset)\n",
        "\n",
        "    #return the average loss and acc from the epoch as well as the logger array       \n",
        "    return epoch_loss, epoch_acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhgkIOQzF78g"
      },
      "source": [
        "# Learning Scheduler from lab 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23opuAocF-9x"
      },
      "source": [
        "#Create a function that will linearly decay the learning rate every epoch\n",
        "def lr_linear_decay(epoch_max, epoch, lr):\n",
        "    lr_adj = ((epoch_max - epoch)/epoch_max)*lr\n",
        "    #update the learning rate parameter of the optimizer\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr_adj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXr4uyTYDs5e"
      },
      "source": [
        "# Run the Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wWijnzGCAVR"
      },
      "source": [
        "#Log the training and validation losses\n",
        "training_loss_logger = []\n",
        "validation_loss_logger = []\n",
        "#Log the training and validation losses\n",
        "training_acc_logger = []\n",
        "validation_acc_logger = []"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "Slljs8y-CBu-",
        "outputId": "50b9a0b9-d28e-4f6b-990e-4f0399c07cde"
      },
      "source": [
        "#This cell implements our training loop\n",
        "\n",
        "#Record the start time\n",
        "Start_time = time.time()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    #Implement the linear decay of the learning rate\n",
        "    #lr_linear_decay(num_epochs, epoch, learning_rate)\n",
        "    \n",
        "    #call the training function and pass training dataloader etc\n",
        "    train_loss = train(gender_classifier2, device, train_loader, optimizer, loss_fun)\n",
        "    \n",
        "    #call the evaluate function and pass validation/training dataloader etc\n",
        "    _, train_acc = evaluate(res_net, device, train_loader, loss_fun)\n",
        "    valid_loss, valid_acc = evaluate(res_net, device, valid_loader, loss_fun)\n",
        "    \n",
        "    training_loss_logger.append(train_loss)\n",
        "    validation_loss_logger.append(valid_loss)\n",
        "    \n",
        "    training_acc_logger.append(train_acc)\n",
        "    validation_acc_logger.append(valid_acc)\n",
        "    #If this model has the highest performace on the validation set \n",
        "    #then save a checkpoint\n",
        "    #{} define a dictionary, each entry of the dictionary is indexed with a string\n",
        "    if (valid_acc > best_valid_acc):\n",
        "        best_valid_acc = valid_acc\n",
        "        if save_checkpoint:\n",
        "            print(\"Saving Model\")\n",
        "            torch.save({\n",
        "                'epoch':                 epoch,\n",
        "                'model_state_dict':      res_net.state_dict(),\n",
        "                'optimizer_state_dict':  optimizer.state_dict(), \n",
        "                'train_acc':             train_acc,\n",
        "                'valid_acc':             valid_acc,\n",
        "            }, save_path)\n",
        "            \n",
        "    print(f'| Epoch: {epoch+1:02} | Train Loss: {train_loss:.3f} | Train Acc: {train_acc*100:05.2f}% | Val. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:05.2f}% |')\n",
        "\n",
        "End_time = time.time()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-35fc670f11cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#call the training function and pass training dataloader etc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgender_classifier2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m#call the evaluate function and pass validation/training dataloader etc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "BBkBGWwfCEys",
        "outputId": "1a481f15-cd79-4059-8152-a969d5471084"
      },
      "source": [
        "print(\"The highest validation accuracy was %.2f%%\" %(best_valid_acc*100))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-63069f97c5bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The highest validation accuracy was %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_valid_acc\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_valid_acc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "1GXdR-hjCF-b",
        "outputId": "c0a4f4fd-ec23-4868-dc91-5c2da0d40011"
      },
      "source": [
        "print(\"Training time %.2f seconds\" %(End_time - Start_time))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4d266aa16725>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training time %.2f seconds\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnd_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mStart_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'End_time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "0YjwkbBECHH8",
        "outputId": "72ef2081-6c92-4645-9f10-58bda4b043b8"
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "train_x = np.linspace(0, num_epochs, len(training_loss_logger))\n",
        "plt.plot(train_x, training_loss_logger, c = \"y\")\n",
        "valid_x = np.linspace(0, num_epochs, len(validation_loss_logger))\n",
        "plt.plot(valid_x, validation_loss_logger, c = \"k\")\n",
        "\n",
        "plt.title(\"ResNet Loss\")\n",
        "plt.legend([\"Training Loss\", \"Validation Loss\"])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f1aff7b9650>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxRNxwBfCILJ"
      },
      "source": [
        "plt.figure(figsize = (10,10))\n",
        "train_x = np.linspace(0, num_epochs, len(training_acc_logger))\n",
        "plt.plot(train_x, training_acc_logger, c = \"y\")\n",
        "valid_x = np.linspace(0, num_epochs, len(validation_acc_logger))\n",
        "plt.plot(valid_x, validation_acc_logger, c = \"k\")\n",
        "\n",
        "plt.title(\"ResNet Acc\")\n",
        "plt.legend([\"Training Acc\", \"Validation Acc\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnm62pPtGBsN"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3dCmfBWGD2Q"
      },
      "source": [
        "#call the evaluate function and pass the evaluation/test dataloader etc\n",
        "test_loss, test_acc = evaluate(res_net, device, test_loader, loss_fun)\n",
        "print(\"Testing: | Loss %.2f | Accuracy %.2f%% |\" %(test_loss, 100*test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb8foAH9EFMf"
      },
      "source": [
        "# Stuff below was for me \n",
        "### - Old dataset types\n",
        "### - Packages to install\n",
        "### - Google mount"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvWB70XUttqu"
      },
      "source": [
        "### Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5Pt9XPvq0ps",
        "outputId": "a19b6ae7-1f47-4fd4-f329-766d81465d13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8qHx-QZJLY3",
        "outputId": "00b9519b-da50-455f-9b2d-e8d56d208e0b"
      },
      "source": [
        "cd drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'drive/MyDrive'\n",
            "/content/drive/MyDrive/Colab Notebooks/ECE4179/course proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrAIHOALrPsr",
        "outputId": "ee84886f-dd92-4761-c5ec-5bddaf01a9d1"
      },
      "source": [
        "cd Colab Notebooks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Colab Notebooks'\n",
            "/content/drive/MyDrive/Colab Notebooks/ECE4179/course proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWWXgnTTrwso",
        "outputId": "1d3e7fa6-d834-4c0f-b672-f26d212693ba"
      },
      "source": [
        "cd ECE4179"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'ECE4179'\n",
            "/content/drive/MyDrive/Colab Notebooks/ECE4179/course proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4THFxuABrzbg",
        "outputId": "6c24a05e-d602-4962-a33d-d7da401fdacd"
      },
      "source": [
        "cd course proj"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'course proj'\n",
            "/content/drive/MyDrive/Colab Notebooks/ECE4179/course proj\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73IKbPdcr5vd",
        "outputId": "75a8b0b8-12df-4141-c6e4-b2da4d7e9c86"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age_gender.csv  Balanced_Set_Model.ipynb  GenderClassifier.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpgLvVVrEXYK"
      },
      "source": [
        "train_transform = transforms.Compose(\n",
        "        [transforms.Resize(args[\"image_size\"]),\n",
        "        transforms.RandomCrop(args[\"crop_size\"]),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean = [0.485, 0.456, 0.406],\n",
        "                             std=[0.229, 0.224, 0.225]),\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQCAfQ1arxGy"
      },
      "source": [
        "# Old Datasets: Celeb Face Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPsJ_XbppyGA"
      },
      "source": [
        "# Packages for Datasets used below\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import os\n",
        "# plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "# Image processing\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "ICYbkZxPhZfw",
        "outputId": "5cbbffc1-e509-4141-f7da-88d40edc52e2"
      },
      "source": [
        "imagenet_data = torchvision.datasets.ImageNet('course proj/img_align_celeba/')\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(imagenet_data,\n",
        "                                          batch_size=32,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-213-94c71da056f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimagenet_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'course proj/img_align_celeba/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m data_loader = torch.utils.data.DataLoader(imagenet_data,\n\u001b[1;32m      4\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, split, download, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_str_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mwnid_to_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_meta_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_archives\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_archives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_integrity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETA_FILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mparse_devkit_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36mparse_devkit_archive\u001b[0;34m(root, file)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mmd5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marchive_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0m_verify_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_tmp_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/imagenet.py\u001b[0m in \u001b[0;36m_verify_archive\u001b[0;34m(root, file, md5)\u001b[0m\n\u001b[1;32m    101\u001b[0m         msg = (\"The archive {} is not present in the root directory or is corrupted. \"\n\u001b[1;32m    102\u001b[0m                \"You need to download it externally and place it in {}.\")\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The archive ILSVRC2012_devkit_t12.tar.gz is not present in the root directory or is corrupted. You need to download it externally and place it in course proj/img_align_celeba/."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqa4O58nqD_B"
      },
      "source": [
        "# Old DataSets: Gender DataSet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMY9TCAHqFGw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7fb7c3e7-f409-4bf8-deb6-8838f552cc64"
      },
      "source": [
        "df = pd.read_csv('../course proj/age_gender.csv')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-24d50265e7eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../course proj/age_gender.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../course proj/age_gender.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GcQMevFiqiom",
        "outputId": "dfde8cdf-2d73-4b8f-eea8-892de6c52e41"
      },
      "source": [
        "print(f'Total Data Points: {df.shape[1]}')\n",
        "print(f'Total columns/Features: {df.shape[0]}\\n\\n')\n",
        "df.info()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-9c4a9a0edf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Total Data Points: {df.shape[1]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Total columns/Features: {df.shape[0]}\\n\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN9ySMDgtFju"
      },
      "source": [
        "df['pixels'] = df['pixels'].apply(lambda x:  np.reshape(np.array(x.split(), dtype=\"float32\"), (48,48)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "392W7QU1tVia"
      },
      "source": [
        "df.gender.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4Y3ARJ6tZ2b"
      },
      "source": [
        "#plot_data(rows=6, cols=7, lower_value=0, upper_value=len(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4u4EUuY9uY10"
      },
      "source": [
        "class get_data(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=125.01632431478356, std=59.44005080507268)\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self,i):\n",
        "        age = df['age'][i]\n",
        "        eth = df['ethnicity'][i]\n",
        "        gender = df['gender'][i]\n",
        "        \n",
        "        im = df['pixels'][i]\n",
        "#         im = np.reshape(im, (48,48))\n",
        "        im = self.transform(im)\n",
        "        \n",
        "        age = torch.tensor(age)\n",
        "        eth = torch.tensor(eth)\n",
        "        gender = torch.tensor(gender)\n",
        "        \n",
        "        return im, age, eth, gender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd5mbQ89ublW"
      },
      "source": [
        "train, test = train_test_split(df, test_size=0.2, random_state=129) \n",
        "\n",
        "print(f'- Number of Datapoints in Training Set: {len(train)}')\n",
        "print(f'- Number of Datapoints in Test Set: {len(test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3h2-6xpugfz"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "use_cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available:\", use_cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if use_cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    BATCH_SIZE=64\n",
        "else:\n",
        "    BATCH_SIZE=32\n",
        "    \n",
        "print('BATCH_SIZE:', BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmie8SAjupX-"
      },
      "source": [
        "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
        "\n",
        "\n",
        "train_loader = DataLoader(get_data(train), batch_size=BATCH_SIZE, shuffle=True, **kwargs)\n",
        "test_loader = DataLoader(get_data(test), batch_size=BATCH_SIZE, shuffle=False, **kwargs)\n",
        "image, age, eth, gender = next(iter(train_loader))\n",
        "gender"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAGZYi3uD1Tz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}